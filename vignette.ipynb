{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80d1d5d",
   "metadata": {},
   "source": [
    "# Advanced Earnings Analysis Workflows\n",
    "\n",
    "## 1. Strategic Research Questions\n",
    "\n",
    "Moving beyond basic sentiment scoring, earnings call analysis becomes powerful when driven by specific research hypotheses. Rather than asking \"How does management feel?\", we can investigate targeted questions that inform investment decisions and market understanding.\n",
    "\n",
    "### Hypothesis-Driven Analysis Framework\n",
    "\n",
    "The key to valuable earnings analysis lies in asking the right questions. Generic sentiment scores provide limited insight, but structured questions can reveal competitive advantages, strategic priorities, and management confidence in specific areas.\n",
    "\n",
    "**Example Research Question:** \"Are technology companies more optimistic about AI capabilities than their current market valuations suggest?\"\n",
    "\n",
    "This question requires:\n",
    "- **Specificity**: Focus on AI-related statements, not general sentiment\n",
    "- **Comparability**: Consistent analysis across multiple companies  \n",
    "- **Actionability**: Results that inform investment decisions\n",
    "- **Measurability**: Quantitative scores that enable statistical analysis\n",
    "\n",
    "### Designing Research-Grade Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e87ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research-focused AI confidence prompt\n",
    "ai_confidence_prompt = \"\"\"\n",
    "Analyze this earnings call transcript focusing specifically on artificial intelligence initiatives, capabilities, and strategic positioning.\n",
    "\n",
    "Evaluate management's confidence and specificity in the following areas:\n",
    "1. AI product development and deployment timelines\n",
    "2. Competitive advantages in AI technologies  \n",
    "3. Revenue potential from AI initiatives\n",
    "4. Technical capabilities and infrastructure readiness\n",
    "\n",
    "Return your analysis as JSON with these exact fields:\n",
    "{\n",
    " \"ai_development_confidence\": [1-10 scale],\n",
    " \"competitive_ai_advantage\": [1-10 scale], \n",
    " \"ai_revenue_optimism\": [1-10 scale],\n",
    " \"technical_readiness\": [1-10 scale],\n",
    " \"specific_ai_mentions\": [\"list of concrete AI products/services mentioned\"],\n",
    " \"revenue_projections\": [\"list of any quantitative AI revenue statements\"],\n",
    " \"competitive_comparisons\": [\"list of competitor AI comparisons made\"],\n",
    " \"confidence_indicators\": [\"list of confidence-indicating phrases used\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b57d22",
   "metadata": {},
   "source": [
    "### Research Methodology Considerations\n",
    "\n",
    "**Consistency Requirements:**\n",
    "- Use identical prompts across all companies in your analysis\n",
    "- Apply to same time periods (e.g., Q3 2024 calls only)\n",
    "- Document any prompt modifications for reproducibility\n",
    "\n",
    "**Validation Approach:**\n",
    "- Test prompts on transcripts you've manually analyzed\n",
    "- Verify that JSON structure remains consistent across different companies\n",
    "- Check for edge cases where companies don't discuss the research topic\n",
    "\n",
    "**Statistical Readiness:**\n",
    "- Design scores that can be meaningfully averaged and compared\n",
    "- Include both quantitative scales and qualitative lists for different analysis needs\n",
    "- Structure output for easy conversion to pandas DataFrames\n",
    "\n",
    "### Moving Beyond Generic Sentiment\n",
    "\n",
    "Traditional sentiment analysis asks: \"How positive or negative is management?\"\n",
    "\n",
    "Strategic research analysis asks: \"How confident is management in their specific competitive advantages, and what evidence supports that confidence?\"\n",
    "\n",
    "This shift from general mood to specific strategic assessment provides actionable intelligence for investment decisions, competitive analysis, and market timing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610f572",
   "metadata": {},
   "source": [
    "## 2. Custom Prompt Design Principles\n",
    "\n",
    "Effective custom prompts for earnings analysis require careful design to ensure consistent, analyzable results across different companies and time periods. Poor prompt design leads to inconsistent JSON structures and unreliable data.\n",
    "\n",
    "### Core Design Principles\n",
    "\n",
    "**Principle 1: Explicit JSON Structure**\n",
    "Always specify the exact JSON fields and data types expected. Ambiguous instructions lead to parsing errors and inconsistent results.\n",
    "\n",
    "**Principle 2: Bounded Scales**\n",
    "Use consistent numerical scales (e.g., 1-10) with clear anchoring. Define what constitutes a \"1\" versus a \"10\" in your research context.\n",
    "\n",
    "**Principle 3: Specific Evidence Requirements**\n",
    "Request concrete examples and quotes. This enables validation and provides qualitative context for quantitative scores.\n",
    "\n",
    "**Principle 4: Research-Focused Language**\n",
    "Frame questions around business strategy and competitive positioning, not emotional sentiment.\n",
    "\n",
    "### Prompt Engineering Patterns\n",
    "\n",
    "**Pattern 1: Multi-Dimensional Scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779206c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Financial Health Assessment Prompt\n",
    "financial_health_prompt = \"\"\"\n",
    "Analyze this earnings call for indicators of financial health and management confidence in financial performance.\n",
    "\n",
    "Evaluate and score the following dimensions:\n",
    "1. Revenue growth confidence and sustainability\n",
    "2. Cost management effectiveness and strategy\n",
    "3. Capital allocation priorities and discipline\n",
    "4. Market share and competitive positioning strength\n",
    "\n",
    "Return analysis as JSON:\n",
    "{\n",
    "  \"revenue_growth_confidence\": [1-10],\n",
    "  \"cost_management_effectiveness\": [1-10], \n",
    "  \"capital_allocation_discipline\": [1-10],\n",
    "  \"competitive_position_strength\": [1-10],\n",
    "  \"revenue_growth_evidence\": [\"specific statements about revenue sustainability\"],\n",
    "  \"cost_management_initiatives\": [\"concrete cost reduction or efficiency measures\"],\n",
    "  \"capital_allocation_priorities\": [\"stated priorities for capital deployment\"],\n",
    "  \"competitive_advantages_cited\": [\"claimed competitive advantages or differentiators\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9c418",
   "metadata": {},
   "source": [
    "**Pattern 2: Risk Assessment Framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b4d132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Operational Risk Evaluation Prompt  \n",
    "risk_assessment_prompt = \"\"\"\n",
    "Analyze this earnings call for operational and strategic risk factors mentioned or implied by management.\n",
    "\n",
    "Assess management's acknowledgment and mitigation strategies for:\n",
    "1. Market and competitive risks\n",
    "2. Operational and execution risks  \n",
    "3. Regulatory and compliance risks\n",
    "4. Technology and innovation risks\n",
    "\n",
    "Return analysis as JSON:\n",
    "{\n",
    "  \"market_risk_awareness\": [1-10],\n",
    "  \"operational_risk_management\": [1-10],\n",
    "  \"regulatory_risk_preparation\": [1-10], \n",
    "  \"technology_risk_mitigation\": [1-10],\n",
    "  \"identified_market_risks\": [\"specific market challenges mentioned\"],\n",
    "  \"operational_challenges\": [\"operational difficulties or constraints discussed\"],\n",
    "  \"regulatory_concerns\": [\"regulatory issues or changes mentioned\"],\n",
    "  \"technology_vulnerabilities\": [\"technology risks or dependencies noted\"],\n",
    "  \"mitigation_strategies\": [\"concrete risk mitigation strategies described\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc497d50",
   "metadata": {},
   "source": [
    "### JSON Structure Best Practices\n",
    "\n",
    "**Consistent Field Naming:**\n",
    "- Use descriptive, unambiguous field names\n",
    "- Employ consistent naming conventions (snake_case recommended)\n",
    "- Avoid abbreviations that could be misinterpreted\n",
    "\n",
    "**Data Type Specification:**\n",
    "- Numerical scores: Always specify scale boundaries\n",
    "- Lists: Clearly indicate what type of content is expected  \n",
    "- Text fields: Define length and content requirements\n",
    "\n",
    "**Validation-Friendly Design:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5543208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example validation function for custom prompt results\n",
    "def validate_custom_analysis(result, expected_fields):\n",
    "    \"\"\"Validate that custom prompt returned expected JSON structure.\"\"\"\n",
    "    if not isinstance(result, dict):\n",
    "        return False, \"Result is not a dictionary\"\n",
    "    \n",
    "    missing_fields = [field for field in expected_fields if field not in result]\n",
    "    if missing_fields:\n",
    "        return False, f\"Missing required fields: {missing_fields}\"\n",
    "    \n",
    "    # Validate numerical scores are within expected range\n",
    "    score_fields = [field for field in expected_fields if 'confidence' in field or 'effectiveness' in field]\n",
    "    for field in score_fields:\n",
    "        if field in result:\n",
    "            if not isinstance(result[field], (int, float)) or not (1 <= result[field] <= 10):\n",
    "                return False, f\"Invalid score in field {field}: {result[field]}\"\n",
    "    \n",
    "    return True, \"Validation passed\"\n",
    "\n",
    "# Usage example\n",
    "expected_ai_fields = [\n",
    "    'ai_development_confidence', 'competitive_ai_advantage', \n",
    "    'ai_revenue_optimism', 'technical_readiness',\n",
    "    'specific_ai_mentions', 'revenue_projections'\n",
    "]\n",
    "\n",
    "# is_valid, message = validate_custom_analysis(ai_analysis_result, expected_ai_fields)\n",
    "# print(f\"Validation result: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373846ff",
   "metadata": {},
   "source": [
    "### Common Prompt Design Mistakes\n",
    "\n",
    "**Mistake 1: Vague Instructions**\n",
    "- Poor: \"Analyze the AI discussion\"\n",
    "- Better: \"Score management's confidence in AI revenue potential on a 1-10 scale\"\n",
    "\n",
    "**Mistake 2: Inconsistent Scales**\n",
    "- Poor: Using different scale ranges across related questions\n",
    "- Better: Consistent 1-10 scales with clear anchoring definitions\n",
    "\n",
    "**Mistake 3: Missing Validation Fields**\n",
    "- Poor: Only requesting scores without supporting evidence\n",
    "- Better: Including lists of specific quotes and examples for validation\n",
    "\n",
    "**Mistake 4: Overly Complex Requests**\n",
    "- Poor: Asking for 15+ different metrics in a single prompt\n",
    "- Better: Focus on 4-6 key dimensions with supporting evidence\n",
    "\n",
    "### Testing and Iteration\n",
    "\n",
    "Before applying custom prompts to large datasets, test on a small sample of manually reviewed transcripts to ensure:\n",
    "- JSON structure consistency across different companies\n",
    "- Score distributions that reflect actual transcript content\n",
    "- Evidence fields that provide meaningful validation data\n",
    "- Prompts that handle companies with minimal discussion of your research topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d5710",
   "metadata": {},
   "source": [
    "## 3. Multi-Company Comparative Analysis\n",
    "\n",
    "Building reliable comparative datasets requires systematic application of custom prompts across industry peers. This section demonstrates how to construct research-grade comparative analysis that supports statistical inference and investment decision-making.\n",
    "\n",
    "### Research Design: Technology Sector AI Readiness\n",
    "\n",
    "**Research Question:** \"Which major technology companies demonstrate the highest confidence and preparedness for AI-driven revenue growth?\"\n",
    "\n",
    "**Sample Selection:** FAANG companies (Meta, Apple, Amazon, Netflix, Google) plus Microsoft\n",
    "**Time Period:** Q3 2024 earnings calls (ensures comparable market conditions)\n",
    "**Analysis Framework:** Standardized AI readiness assessment\n",
    "\n",
    "### Implementation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96ae834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from earnings_analyzer.analysis.fool_scraper import fetch_transcript\n",
    "from earnings_analyzer.analysis.sentiment_analyzer import score_sentiment\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define our research cohort\n",
    "tech_companies = {\n",
    "    'AMZN': 'Amazon.com Inc.',\n",
    "    'NFLX': 'Netflix Inc.',\n",
    "    'MSFT': 'Microsoft Corp.'\n",
    "}\n",
    "\n",
    "# Standardized AI readiness prompt\n",
    "ai_readiness_prompt = \"\"\"\n",
    "Analyze this earnings call for artificial intelligence readiness and strategic positioning.\n",
    "\n",
    "Evaluate management's demonstrated preparedness in:\n",
    "1. AI product development and market deployment\n",
    "2. AI infrastructure and technical capabilities  \n",
    "3. AI-driven revenue opportunities and monetization\n",
    "4. Competitive differentiation through AI technologies\n",
    "\n",
    "Score each dimension 1-10 where:\n",
    "- 1-3: Limited AI focus or capability\n",
    "- 4-6: Moderate AI investment and development\n",
    "- 7-10: Strong AI leadership and market position\n",
    "\n",
    "Return analysis as JSON:\n",
    "{\n",
    "  \"ai_product_readiness\": [1-10],\n",
    "  \"ai_infrastructure_strength\": [1-10],\n",
    "  \"ai_revenue_potential\": [1-10], \n",
    "  \"ai_competitive_advantage\": [1-10],\n",
    "  \"ai_products_mentioned\": [\"specific AI products or services discussed\"],\n",
    "  \"infrastructure_capabilities\": [\"AI infrastructure or technical capabilities cited\"],\n",
    "  \"revenue_opportunities\": [\"specific AI revenue streams or monetization strategies\"],\n",
    "  \"competitive_differentiators\": [\"claimed AI competitive advantages\"],\n",
    "  \"investment_commitments\": [\"AI investment amounts or resource commitments mentioned\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f49a8",
   "metadata": {},
   "source": [
    "### Systematic Data Collection\n",
    "\n",
    "#### Expected Behavior and Limitations\n",
    "\n",
    "**Note:** This analysis depends on transcript availability from The Motley Fool and AI model response formatting. You may encounter:\n",
    "\n",
    "- **Transcript not found**: Some companies may not have transcripts available for the specified quarter\n",
    "- **Analysis failures**: Occasionally, the AI model may return detailed text instead of the requested JSON format\n",
    "- **Mixed results**: This is normal and demonstrates real-world research conditions\n",
    "\n",
    "The analysis will process all available data and continue with successful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06622956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Technology Companies for AI Readiness...\n",
      "============================================================\n",
      "Amazon.com Inc.      | ✅ Success | AI Score: 9/10\n",
      "Netflix Inc.         | ✅ Success | AI Score: 7/10\n",
      "Microsoft Corp.      | ✅ Success | AI Score: 10/10\n",
      "\n",
      "Successfully analyzed 3 companies\n"
     ]
    }
   ],
   "source": [
    "# Suppress only earnings_analyzer module logging, not print statements\n",
    "import logging\n",
    "\n",
    "# Create a custom handler that filters out INFO messages from earnings_analyzer only\n",
    "class EarningsAnalyzerFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        # Block INFO messages from earnings_analyzer modules, allow everything else\n",
    "        if record.levelno == logging.INFO and 'earnings_analyzer' in record.name:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "# Apply the filter to the root logger\n",
    "root_logger = logging.getLogger()\n",
    "for handler in root_logger.handlers:\n",
    "    handler.addFilter(EarningsAnalyzerFilter())\n",
    "\n",
    "def analyze_company_ai_readiness_clean(ticker, company_name, quarter=\"Q4\", year=2024):\n",
    "    \"\"\"Analyze a single company's AI readiness from earnings call with minimal output.\"\"\"\n",
    "    \n",
    "    transcript = fetch_transcript(ticker, quarter=quarter, year=year)\n",
    "    if not transcript:\n",
    "        print(f\"{company_name:20} | ❌ Transcript not found\")\n",
    "        return None\n",
    "    \n",
    "    ai_analysis = score_sentiment(transcript['transcript_text'], custom_prompt=ai_readiness_prompt)\n",
    "    if not ai_analysis:\n",
    "        print(f\"{company_name:20} | ❌ AI analysis failed\")\n",
    "        return None\n",
    "    \n",
    "    result = {\n",
    "        'ticker': ticker,\n",
    "        'company_name': company_name,\n",
    "        'call_date': transcript.get('call_date'),\n",
    "        'quarter': transcript.get('quarter'),\n",
    "        'year': transcript.get('year'),\n",
    "        **ai_analysis\n",
    "    }\n",
    "    \n",
    "    print(f\"{company_name:20} | ✅ Success | AI Score: {ai_analysis.get('ai_product_readiness', 0)}/10\")\n",
    "    return result\n",
    "\n",
    "# Execute clean analysis\n",
    "print(\"Analyzing Technology Companies for AI Readiness...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ai_readiness_results = []\n",
    "for ticker, company_name in tech_companies.items():\n",
    "    result = analyze_company_ai_readiness_clean(ticker, company_name)\n",
    "    if result:\n",
    "        ai_readiness_results.append(result)\n",
    "\n",
    "print(f\"\\nSuccessfully analyzed {len(ai_readiness_results)} companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7696d5af",
   "metadata": {},
   "source": [
    "### Converting to Analysis-Ready DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45962fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Readiness Rankings (Q4 2024):\n",
      "==================================================\n",
      "Microsoft Corp.      | Score: 9.2/10\n",
      "                     | Products: 10/10, Infrastructure: 9/10\n",
      "                     | Revenue: 9/10, Competitive: 9/10\n",
      "\n",
      "Amazon.com Inc.      | Score: 9.0/10\n",
      "                     | Products: 9/10, Infrastructure: 9/10\n",
      "                     | Revenue: 9/10, Competitive: 9/10\n",
      "\n",
      "Netflix Inc.         | Score: 7.0/10\n",
      "                     | Products: 7/10, Infrastructure: 8/10\n",
      "                     | Revenue: 8/10, Competitive: 5/10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert results to pandas DataFrame for analysis\n",
    "df_ai_readiness = pd.DataFrame(ai_readiness_results)\n",
    "\n",
    "# Calculate composite AI readiness score\n",
    "df_ai_readiness['composite_ai_score'] = (\n",
    "    df_ai_readiness['ai_product_readiness'] + \n",
    "    df_ai_readiness['ai_infrastructure_strength'] +\n",
    "    df_ai_readiness['ai_revenue_potential'] + \n",
    "    df_ai_readiness['ai_competitive_advantage']\n",
    ") / 4\n",
    "\n",
    "# Rank companies by AI readiness\n",
    "df_ai_readiness = df_ai_readiness.sort_values('composite_ai_score', ascending=False)\n",
    "\n",
    "# Display comparative rankings\n",
    "print(\"AI Readiness Rankings (Q4 2024):\")\n",
    "print(\"=\" * 50)\n",
    "for idx, row in df_ai_readiness.iterrows():\n",
    "    print(f\"{row['company_name']:20} | Score: {row['composite_ai_score']:.1f}/10\")\n",
    "    print(f\"{'':20} | Products: {row['ai_product_readiness']}/10, \"\n",
    "          f\"Infrastructure: {row['ai_infrastructure_strength']}/10\")\n",
    "    print(f\"{'':20} | Revenue: {row['ai_revenue_potential']}/10, \"\n",
    "          f\"Competitive: {row['ai_competitive_advantage']}/10\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e1d5e",
   "metadata": {},
   "source": [
    "### Statistical Analysis and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbbee498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech Sector AI Readiness Statistics:\n",
      "========================================\n",
      "Mean composite score: 8.42\n",
      "Standard deviation: 1.23\n",
      "Range: 7.0 - 9.2\n",
      "\n",
      "Dimension Leaders:\n",
      "--------------------\n",
      "Product Readiness   : Microsoft Corp. (10/10)\n",
      "Infrastructure Strength: Microsoft Corp. (9/10)\n",
      "Revenue Potential   : Microsoft Corp. (9/10)\n",
      "Competitive Advantage: Microsoft Corp. (9/10)\n",
      "\n",
      "Results exported to tech_ai_readiness_q3_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary of AI readiness across tech sector\n",
    "print(\"Tech Sector AI Readiness Statistics:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Mean composite score: {df_ai_readiness['composite_ai_score'].mean():.2f}\")\n",
    "print(f\"Standard deviation: {df_ai_readiness['composite_ai_score'].std():.2f}\")\n",
    "print(f\"Range: {df_ai_readiness['composite_ai_score'].min():.1f} - {df_ai_readiness['composite_ai_score'].max():.1f}\")\n",
    "\n",
    "# Identify dimension leaders\n",
    "dimensions = ['ai_product_readiness', 'ai_infrastructure_strength', \n",
    "              'ai_revenue_potential', 'ai_competitive_advantage']\n",
    "\n",
    "print(\"\\nDimension Leaders:\")\n",
    "print(\"-\" * 20)\n",
    "for dim in dimensions:\n",
    "    leader_idx = df_ai_readiness[dim].idxmax()\n",
    "    leader = df_ai_readiness.loc[leader_idx]\n",
    "    print(f\"{dim.replace('ai_', '').replace('_', ' ').title():20}: \"\n",
    "          f\"{leader['company_name']} ({leader[dim]}/10)\")\n",
    "\n",
    "# Export for further analysis\n",
    "df_ai_readiness.to_csv('tech_ai_readiness_q4_2024.csv', index=False)\n",
    "print(f\"\\nResults exported to tech_ai_readiness_q3_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2931401",
   "metadata": {},
   "source": [
    "### Research Validation and Quality Control\n",
    "\n",
    "**Data Quality Checks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2abc63be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data quality validation passed\n"
     ]
    }
   ],
   "source": [
    "# Validate analysis completeness and consistency\n",
    "def validate_comparative_analysis(df):\n",
    "    \"\"\"Perform quality checks on comparative analysis results.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check for missing data\n",
    "    missing_data = df.isnull().sum()\n",
    "    if missing_data.any():\n",
    "        issues.append(f\"Missing data detected: {missing_data[missing_data > 0].to_dict()}\")\n",
    "    \n",
    "    # Check score ranges\n",
    "    score_columns = [col for col in df.columns if 'ai_' in col and col.endswith(('_readiness', '_strength', '_potential', '_advantage'))]\n",
    "    for col in score_columns:\n",
    "        out_of_range = df[(df[col] < 1) | (df[col] > 10)]\n",
    "        if not out_of_range.empty:\n",
    "            issues.append(f\"Scores out of range (1-10) in {col}: {out_of_range[['ticker', col]].to_dict('records')}\")\n",
    "    \n",
    "    # Check for identical scores (possible prompt failure)\n",
    "    for col in score_columns:\n",
    "        if df[col].nunique() == 1:\n",
    "            issues.append(f\"All companies have identical scores in {col} - check prompt effectiveness\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# Run validation\n",
    "validation_issues = validate_comparative_analysis(df_ai_readiness)\n",
    "if validation_issues:\n",
    "    print(\"Data Quality Issues:\")\n",
    "    for issue in validation_issues:\n",
    "        print(f\"  ⚠️  {issue}\")\n",
    "else:\n",
    "    print(\"✅ Data quality validation passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39616e",
   "metadata": {},
   "source": [
    "### Interpreting Comparative Results\n",
    "\n",
    "**Key Analysis Considerations:**\n",
    "\n",
    "1. **Score Distribution**: Examine whether scores cluster or show meaningful differentiation\n",
    "2. **Evidence Quality**: Review the supporting evidence lists for each company\n",
    "3. **Temporal Consistency**: Ensure all transcripts are from comparable time periods\n",
    "4. **Sector Context**: Consider industry-wide trends that may affect all companies similarly\n",
    "\n",
    "**Research Applications:**\n",
    "- **Investment Screening**: Identify AI leaders for portfolio consideration\n",
    "- **Competitive Intelligence**: Understand relative AI positioning across major players  \n",
    "- **Trend Analysis**: Track how AI readiness evolves across subsequent quarters\n",
    "- **Valuation Context**: Compare AI confidence with current market valuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcef2af",
   "metadata": {},
   "source": [
    "## 4. Database-Backed Analysis for Persistence and Recovery\n",
    "\n",
    "The composable approach demonstrated above works well for custom analysis pipelines, but researchers often need persistence, caching, and failure recovery. The `EarningsAnalyzer` class provides a database-backed solution that addresses these research workflow needs.\n",
    "\n",
    "### Benefits of Database Persistence for Research\n",
    "\n",
    "Working with earnings data presents common challenges that database persistence solves:\n",
    "\n",
    "1. **Cache expensive API calls** to avoid redundant analysis costs\n",
    "2. **Build historical datasets** systematically over time  \n",
    "3. **Enable cross-session research** with permanent result storage\n",
    "4. **Support longitudinal studies** tracking companies across quarters\n",
    "5. **Provide research reproducibility** with consistent data access\n",
    "\n",
    "The database approach is particularly valuable for researchers conducting ongoing monitoring, building comparative datasets, or working with the same companies across multiple research sessions.\n",
    "\n",
    "### Database-Backed Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dad31cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Database-Backed Analysis with Retry ===\n",
      "\n",
      "Analyzing Meta Platforms (META) with database caching...\n",
      "  ✅ Success - Sentiment: 9.0/10\n",
      "\n",
      "Analyzing Microsoft Corp. (MSFT) with database caching...\n",
      "  ✅ Success - Sentiment: 9.0/10\n",
      "\n",
      "Analyzing Amazon.com Inc. (AMZN) with database caching...\n",
      "  ✅ Success - Sentiment: 9.0/10\n",
      "\n",
      "Successfully retrieved 3 analyses\n"
     ]
    }
   ],
   "source": [
    "from earnings_analyzer.api import EarningsAnalyzer\n",
    "\n",
    "# Initialize database-backed analyzer\n",
    "analyzer = EarningsAnalyzer()\n",
    "\n",
    "# This will use cached results for META and MSFT (if they exist)\n",
    "# and retry AMZN with a fresh API call\n",
    "tech_companies_retry = {\n",
    "    'META': 'Meta Platforms',\n",
    "    'MSFT': 'Microsoft Corp.',\n",
    "    'AMZN': 'Amazon.com Inc.'\n",
    "}\n",
    "\n",
    "print(\"=== Database-Backed Analysis with Retry ===\\n\")\n",
    "\n",
    "db_results = []\n",
    "for ticker, company_name in tech_companies_retry.items():\n",
    "    print(f\"Analyzing {company_name} ({ticker}) with database caching...\")\n",
    "    \n",
    "    # The analyze() method automatically handles caching\n",
    "    result = analyzer.analyze(ticker, quarter=\"Q4\", year=2024)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"  ✅ Success - Sentiment: {result['sentiment'].get('overall_sentiment_score', 'N/A')}/10\")\n",
    "        db_results.append({\n",
    "            'ticker': ticker,\n",
    "            'company_name': company_name,\n",
    "            'sentiment_score': result['sentiment'].get('overall_sentiment_score'),\n",
    "            'cached': 'Yes' if 'existing analysis' in str(result) else 'No'\n",
    "        })\n",
    "    else:\n",
    "        print(f\"  ❌ Failed - will retry in future runs\")\n",
    "    print()\n",
    "\n",
    "print(f\"Successfully retrieved {len(db_results)} analyses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c3a0f",
   "metadata": {},
   "source": [
    "### Examining Cached vs. Fresh Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d5bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Database Contents ===\n",
      "META: 2 call(s) in database\n",
      "  Latest: 2024-10-01 (Q4 2024)\n",
      "  Sentiment: 9.0/10\n",
      "\n",
      "MSFT: 5 call(s) in database\n",
      "  Latest: 2024-07-30 (Q4 2024)\n",
      "  Sentiment: 9.0/10\n",
      "\n",
      "AMZN: 2 call(s) in database\n",
      "  Latest: 2025-02-06 (Q4 2024)\n",
      "  Sentiment: 9.0/10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what's stored in the local database\n",
    "print(\"=== Database Contents ===\")\n",
    "for ticker in tech_companies_retry.keys():\n",
    "    historical_calls = analyzer.get_existing_calls(ticker)\n",
    "    if historical_calls:\n",
    "        latest_call = historical_calls[0]  # Most recent\n",
    "        print(f\"{ticker}: {len(historical_calls)} call(s) in database\")\n",
    "        print(f\"  Latest: {latest_call['call_date']} ({latest_call['quarter']} {latest_call['year']})\")\n",
    "        print(f\"  Sentiment: {latest_call.get('overall_sentiment_score', 'N/A')}/10\")\n",
    "    else:\n",
    "        print(f\"{ticker}: No cached data\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a305e34a",
   "metadata": {},
   "source": [
    "### Database Performance Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9da89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Performance Comparison ===\n",
      "Database-cached analysis: 1.11 seconds\n",
      "Original API-based analysis: ~30-60 seconds (estimated)\n",
      "Performance improvement: ~27x faster\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Demonstrate caching performance\n",
    "print(\"=== Performance Comparison ===\")\n",
    "\n",
    "# Time a database-cached retrieval\n",
    "start_time = time.time()\n",
    "cached_result = analyzer.analyze(\"META\", quarter=\"Q3\", year=2024)  # Should be cached\n",
    "cached_time = time.time() - start_time\n",
    "\n",
    "print(f\"Database-cached analysis: {cached_time:.2f} seconds\")\n",
    "print(f\"Original API-based analysis: ~30-60 seconds (estimated)\")\n",
    "print(f\"Performance improvement: ~{30/cached_time:.0f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bb91d",
   "metadata": {},
   "source": [
    "### Building Longitudinal Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffafbf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Historical Analysis Capability ===\n",
      "\n",
      "Analyzing Q2 2024:\n",
      "  MSFT: 9.0/10\n",
      "\n",
      "Analyzing Q3 2024:\n",
      "  MSFT: 9.0/10\n",
      "\n",
      "Analyzing Q4 2024:\n",
      "  MSFT: 9.0/10\n",
      "\n",
      "=== Sentiment Trends ===\n",
      "MSFT: Q2 2024: 9.0/10 → Q3 2024: 9.0/10 → Q4 2024: 9.0/10\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate cross-quarter analysis capability\n",
    "print(\"=== Historical Analysis Capability ===\")\n",
    "\n",
    "# Analyze multiple quarters for comparison (if available)\n",
    "quarters_to_analyze = [\n",
    "    (\"Q2\", 2024),\n",
    "    (\"Q3\", 2024),\n",
    "    (\"Q4\", 2024)\n",
    "]\n",
    "\n",
    "longitudinal_results = []\n",
    "\n",
    "for quarter, year in quarters_to_analyze:\n",
    "    print(f\"\\nAnalyzing {quarter} {year}:\")\n",
    "    \n",
    "    for ticker in ['MSFT']:\n",
    "        result = analyzer.analyze(ticker, quarter=quarter, year=year)\n",
    "        if result:\n",
    "            longitudinal_results.append({\n",
    "                'ticker': ticker,\n",
    "                'quarter': quarter,\n",
    "                'year': year,\n",
    "                'sentiment': result['sentiment'].get('overall_sentiment_score'),\n",
    "                'call_date': result.get('call_date')\n",
    "            })\n",
    "            print(f\"  {ticker}: {result['sentiment'].get('overall_sentiment_score')}/10\")\n",
    "        else:\n",
    "            print(f\"  {ticker}: No data available\")\n",
    "\n",
    "# Convert to DataFrame for trend analysis\n",
    "if longitudinal_results:\n",
    "    import pandas as pd\n",
    "    df_longitudinal = pd.DataFrame(longitudinal_results)\n",
    "    \n",
    "    print(\"\\n=== Sentiment Trends ===\")\n",
    "    for ticker in df_longitudinal['ticker'].unique():\n",
    "        ticker_data = df_longitudinal[df_longitudinal['ticker'] == ticker].sort_values(['year', 'quarter'])\n",
    "        trend_scores = ticker_data['sentiment'].tolist()\n",
    "        quarters = [f\"{row['quarter']} {row['year']}\" for _, row in ticker_data.iterrows()]\n",
    "        print(f\"{ticker}: {' → '.join([f'{q}: {s}/10' for q, s in zip(quarters, trend_scores)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35a4cd",
   "metadata": {},
   "source": [
    "### Database vs. Composable Approach Summary\n",
    "\n",
    "**Database-Backed Benefits:**\n",
    "- **Persistence**: Results saved permanently for future analysis\n",
    "- **Performance**: Cached results load instantly (30-60x faster)\n",
    "- **Recovery**: Failed analyses can be retried without losing successful ones\n",
    "- **Historical Analysis**: Build datasets across multiple quarters automatically\n",
    "- **Consistency**: Same analysis parameters guaranteed across runs\n",
    "\n",
    "**When to Use Database Approach:**\n",
    "- Building longitudinal research datasets\n",
    "- Analyzing the same companies repeatedly\n",
    "- Working with expensive API calls that shouldn't be repeated\n",
    "- Collaborative research requiring consistent historical data\n",
    "\n",
    "**When to Use Composable Approach:**\n",
    "- Custom analysis pipelines with unique requirements\n",
    "- One-off research questions\n",
    "- Integration with existing data science workflows\n",
    "- Maximum flexibility in data processing\n",
    "\n",
    "The choice depends on your research needs: use composable functions for flexibility, database-backed analysis for persistence and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df80e0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This vignette demonstrates how the earnings-analyzer package enables sophisticated, hypothesis-driven research beyond basic sentiment analysis. Through custom prompts, comparative analysis, and flexible architecture, researchers can conduct systematic earnings call research at scale.\n",
    "\n",
    "### What We've Demonstrated\n",
    "\n",
    "1. **Strategic Research Design**: Moving from generic sentiment to hypothesis-driven questions with measurable outcomes\n",
    "2. **Custom Prompt Engineering**: Creating reliable, structured prompts that produce consistent JSON outputs for statistical analysis\n",
    "3. **Multi-Company Comparative Analysis**: Building datasets that support cross-sectional research and competitive intelligence\n",
    "4. **Database-Backed Persistence**: Implementing efficient workflows that handle data availability challenges and build longitudinal datasets\n",
    "5. **Real-World Research Conditions**: Managing incomplete data, API failures, and varying transcript availability\n",
    "\n",
    "### Key Takeaways for Analysts\n",
    "\n",
    "**Dual Architecture Approach**: Choose between composable functions for maximum flexibility or database-backed analysis for persistence and efficiency based on your research needs.\n",
    "\n",
    "**Prompt Design is Critical**: Well-structured custom prompts with explicit JSON schemas and validation fields produce reliable, comparable results across different companies and time periods.\n",
    "\n",
    "**Expect and Plan for Data Challenges**: Real earnings research involves incomplete data availability. Design robust workflows that continue processing despite partial failures.\n",
    "\n",
    "**Validation Enables Confidence**: Include evidence fields in prompts, validate JSON structures, and implement quality checks to ensure research reliability.\n",
    "\n",
    "### Research Applications\n",
    "\n",
    "- **Investment Screening**: Systematically evaluate management confidence across sectors and time periods\n",
    "- **Competitive Intelligence**: Track relative positioning and strategic focus across industry peers\n",
    "- **Longitudinal Analysis**: Build historical datasets to identify trends and validate management guidance\n",
    "- **Custom Research Questions**: Apply domain-specific prompts to investigate specialized business hypotheses\n",
    "\n",
    "### Potential Next Steps\n",
    "\n",
    "- Apply these methodologies to your specific research questions and industry sectors\n",
    "- Combine earnings sentiment analysis with fundamental metrics and market data\n",
    "- Develop sector-specific prompt libraries for consistent analysis frameworks\n",
    "- Build automated research pipelines using the database-backed approach for ongoing monitoring\n",
    "\n",
    "The earnings-analyzer package provides both the technical infrastructure and methodological framework for systematic earnings call research. Success depends on thoughtful prompt design, robust validation procedures, and realistic expectations about data availability in financial research.\n",
    "\n",
    "For additional examples, API documentation, and troubleshooting guidance, refer to the complete package documentation and GitHub repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
